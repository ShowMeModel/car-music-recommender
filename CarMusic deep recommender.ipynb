{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data science toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.evaluation import *\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.factorization.representations import BilinearNet\n",
    "from spotlight.layers import BloomEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import sparse_adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.evaluation import mrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset_aggr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = dataset.UserID.values\n",
    "item_ids = dataset.ItemID.values\n",
    "\n",
    "ratings = dataset.avg_rating.values\n",
    "\n",
    "# num_users = len(set(user_ids)) - set automaticly\n",
    "# num_items = len(set(item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = Interactions(user_ids = np.array(user_ids, dtype=np.int32),\n",
    "                            item_ids = np.array(item_ids, dtype=np.int32),\n",
    "                            ratings = np.array(ratings, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = user_based_train_test_split(interactions, test_percentage=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check train-test proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Interactions dataset (1043 users x 763 items x 656 interactions)>,\n",
       " <Interactions dataset (1043 users x 763 items x 274 interactions)>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"implicit factorization model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImplicitFactorizationModel(loss='adaptive_hinge', \n",
    "                                   embedding_dim=128, \n",
    "                                   n_iter=100, \n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=0.005,\n",
    "                                   l2=1e-6,\n",
    "                                   optimizer_func=sparse_adam.SparseAdam,\n",
    "                                   sparse=True,\n",
    "                                   num_negative_samples=10)\n",
    "\n",
    "# It takes around 1-3 minutes on a CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, verbose=False)\n",
    "\n",
    "# This should take no more than 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mrr = mrr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg mrr score (for test data) is 0.026739688722935646'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Avg mrr score (for test data) is {avg_mrr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = rmse_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data) is 2.5198733806610107'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'RMSE score (for test data) is {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall at k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [1.  1.  1.  0.5 1.  1.  0.6 1.  1.  0.5 0.2 1.  0.5 0.5 0.1 1.  1.  1.\n",
      " 1.  0.4 1.  0.3 0.5 1.  0.5 1.  1.  0.1 1.  1.  1.  1. ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=32, minmax=(0.1, 1.0), mean=0.771875, variance=0.10015120967741935, skewness=-0.8668884123413311, kurtosis=-0.7722939722185149)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall per user: [1.         0.33333333 0.83333333 1.         0.47619048 0.1010101\n",
      " 1.         0.4        0.14285714 1.         1.         0.66666667\n",
      " 1.         1.         1.         0.66666667 0.4        1.\n",
      " 0.25       1.         0.5        1.         1.         1.\n",
      " 1.         0.5        0.0862069  1.         0.5        0.4\n",
      " 0.625      1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall per user: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=32, minmax=(0.08620689655172414, 1.0), mean=0.7150395192690451, variance=0.10585036113274789, skewness=-0.5615055670941068, kurtosis=-1.161261458133152)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.  0.3 1.  0.  0.1 0.  0.  0.1 0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=10, minmax=(0.0, 1.0), mean=0.15, variance=0.09833333333333333, skewness=2.2675633295781363, kurtosis=3.7102365220722033)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall per user: [0.         0.04285714 0.07194245 0.         0.1        0.\n",
      " 0.         0.2        0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall per user: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=10, minmax=(0.0, 0.2), mean=0.04147995889003084, variance=0.004422953371262761, skewness=1.5066110907220818, kurtosis=1.1765322639546207)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"explicit factorization model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExplicitFactorizationModel(loss='poisson', \n",
    "                                   embedding_dim=128, \n",
    "                                   n_iter=150, \n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=0.005,\n",
    "                                   l2=1e-6,\n",
    "                                   optimizer_func=sparse_adam.SparseAdam,\n",
    "                                   sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, verbose=False)\n",
    "\n",
    "# It takes around 1-3 minutes on a CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mrr = mrr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg mrr score (for test data) is 0.037557012727262064'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Avg mrr score (for test data) is {avg_mrr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = rmse_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data) is 1.7787281274795532'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'RMSE score (for test data) is {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.  0.5 1.  0.  0.  0.1 0.1 0.2 0.  0. ]\n",
      "DescribeResult(nobs=10, minmax=(0.0, 1.0), mean=0.19, variance=0.10544444444444447, skewness=1.797450224429637, kurtosis=1.9561315166205677)\n",
      "Recall per user: [0.         0.07142857 0.07194245 0.         0.         0.1\n",
      " 0.2        0.4        0.         0.        ]\n",
      "DescribeResult(nobs=10, minmax=(0.0, 0.4), mean=0.0843371017471737, variance=0.016572254338652115, skewness=1.6470441745565685, kurtosis=1.6574059636006355)\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')\n",
    "print(describe(precision))\n",
    "print(f'Recall per user: {recall}')\n",
    "print(describe(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model bloom embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_ratio = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = BloomEmbedding(interactions.num_users, 32,\n",
    "                                 compression_ratio=compression_ratio,\n",
    "                                 num_hash_functions=2)\n",
    "\n",
    "item_embeddings = BloomEmbedding(interactions.num_items, 32,\n",
    "                                 compression_ratio=compression_ratio,\n",
    "                                 num_hash_functions=2)\n",
    "\n",
    "network = BilinearNet(interactions.num_users,\n",
    "                      interactions.num_items,\n",
    "                      user_embedding_layer=user_embeddings,\n",
    "                      item_embedding_layer=item_embeddings)\n",
    "\n",
    "model = ExplicitFactorizationModel(loss='poisson',\n",
    "                                   n_iter=150,\n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=1e-2,\n",
    "                                   l2=1e-6,\n",
    "                                   representation=network,\n",
    "                                   sparse=True,\n",
    "                                   use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg mrr score is 0.028275384158525645'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr = mrr_score(model, test, train=train)\n",
    "f'Avg mrr score is {np.mean(mrr)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data) is 1.6212029457092285'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = rmse_score(model, test)\n",
    "f'RMSE score (for test data) is {rmse}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.  0.7 1.  0.  0.  0.1 0.1 0.  0.  0. ]\n",
      "DescribeResult(nobs=10, minmax=(0.0, 1.0), mean=0.19, variance=0.1276666666666667, skewness=1.5956848217809907, kurtosis=0.8332776599926821)\n",
      "Recall per user: [0.         0.1        0.07194245 0.         0.         0.1\n",
      " 0.2        0.         0.         0.        ]\n",
      "DescribeResult(nobs=10, minmax=(0.0, 0.2), mean=0.04719424460431655, variance=0.004766972033883685, skewness=1.1554269614124637, kurtosis=0.21025845544285238)\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')\n",
    "print(describe(precision))\n",
    "print(f'Recall per user: {recall}')\n",
    "print(describe(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unaggregated set, explicit model (with ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = dataset.UserID.values\n",
    "item_ids = dataset.ItemID.values\n",
    "\n",
    "ratings = dataset.Rating.values\n",
    "\n",
    "interactions = Interactions(user_ids = np.array(user_ids, dtype=np.int32),\n",
    "                            item_ids = np.array(item_ids, dtype=np.int32),\n",
    "                            ratings = np.array(ratings, dtype=np.float32))\n",
    "\n",
    "train, test = user_based_train_test_split(interactions, test_percentage=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Interactions dataset (1043 users x 763 items x 3808 interactions)>,\n",
       " <Interactions dataset (1043 users x 763 items x 204 interactions)>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExplicitFactorizationModel(loss='poisson', \n",
    "                                   embedding_dim=256, \n",
    "                                   n_iter=200, \n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=0.005,\n",
    "                                   l2=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train)\n",
    "\n",
    "# This can take up to 10 minutes on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg mrr score is 0.029043451390917196'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr = mrr_score(model, test, train=train)\n",
    "f'Avg mrr score is {np.mean(mrr)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data) is 1.6366691589355469'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = rmse_score(model, test)\n",
    "f'RMSE score (for test data) is {rmse}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.2 0.3 0.  0.  0. ]\n",
      "DescribeResult(nobs=5, minmax=(0.0, 0.3), mean=0.1, variance=0.020000000000000004, skewness=0.5929270612815708, kurtosis=-1.4375000000000009)\n",
      "Recall per user: [0.0952381 0.3       0.        0.        0.       ]\n",
      "DescribeResult(nobs=5, minmax=(0.0, 0.3), mean=0.07904761904761905, variance=0.016956916099773244, skewness=1.1784018350520786, kurtosis=-0.28231835403999783)\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')\n",
    "print(describe(precision))\n",
    "print(f'Recall per user: {recall}')\n",
    "print(describe(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite no user and item features used by the algorithms, we managed to get 1.5 RMSE and 20% precision at k-10. For RMSE, the performance is below algorithms like ALS or SVD. Yet, precision was closer to current state of art algorithms like SAR or NCF. Reference - https://github.com/microsoft/recommenders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
